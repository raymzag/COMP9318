{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9318 Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for **COMP9318-lab3**.\n",
    "\n",
    "* You are required to complete your implementation in a file `submission.py` provided along with this notebook.\n",
    "\n",
    "* You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "* You can submit your implementation for **lab3** via following link: https://kg.cse.unsw.edu.au:8318/lab3/ .\n",
    "\n",
    "* For each question, we have provided you with detailed instructions along with question headings. In case of any problem, you can post your query @ Piazza.\n",
    "\n",
    "\n",
    "* You are allowed to add other functions and/or import modules (you may have to in this lab), but you are not allowed to define global variables. **Only functions are allowed** in `submission.py`. \n",
    "\n",
    "* You should not import unnecessary modules/libraries, failing to import such modules at test time will lead to errors.\n",
    "\n",
    "* We will provide immediate feedback on your submission. You can access your scores using the online submission portal on the same day. \n",
    "\n",
    "* For **Final Evaluation** we will be using a different dataset, so your final scores may vary.  \n",
    "\n",
    "* You are allowed to submit as many times as you want before the deadline, but **ONLY the latest version will be kept and marked**.\n",
    "\n",
    "* Submission deadline for this assignment is **23:59:59 on 2nd May, 2018**. We will **not** accept any late submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-1: Text Classification using Multinomial Naive Bayes\n",
    "\n",
    "You are required to implement a multinomial naive bayes classifier to predict spam SMS.\n",
    "\n",
    "The training data is a set of SMS categoried into `spam` and `ham`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv('./asset/data.txt', sep='\\t')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement a unigram model, first we tokenize the text. We use the count corresponding to each token (word) in the SMS as its feature (i.e., bag of words). We store the features and catrgorical information for each SMS in a `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sms):\n",
    "    return sms.split(' ')\n",
    "\n",
    "def get_freq_of_tokens(sms):\n",
    "    tokens = {}\n",
    "    for token in tokenize(sms):\n",
    "        if token not in tokens:\n",
    "            tokens[token] = 1\n",
    "        else:\n",
    "            tokens[token] += 1\n",
    "    return tokens\n",
    "\n",
    "training_data = []\n",
    "for index in range(len(raw_data)):\n",
    "    training_data.append((get_freq_of_tokens(raw_data.iloc[index].text), raw_data.iloc[index].category))\n",
    "\n",
    "# Nc_count = [row[1] for row in training_data].count('ham')\n",
    "# print(len(training_data[-1][0].keys()))\n",
    "# print(all_words[-31:])\n",
    "# from collections import defaultdict\n",
    "\n",
    "# all_words = set([word for row in training_data for word in row[0].keys()])\n",
    "# N = len(training_data)\n",
    "# hams = []\n",
    "# spams = []\n",
    "# for row in training_data:\n",
    "#     if row[1] == 'ham':\n",
    "#         hams.append(row[0])\n",
    "#     else:\n",
    "#         spams.append(row[0])\n",
    "\n",
    "# ham_dd = defaultdict(int)\n",
    "# spam_dd = defaultdict(int)\n",
    "# for row in training_data:\n",
    "#     if row[1] == 'ham':\n",
    "#         for k, v in row[0].items():\n",
    "#             ham_dd[k] += v\n",
    "#     else:\n",
    "#         for k, v in row[0].items():\n",
    "#             spam_dd[k] += v\n",
    "# for ham_dict in hams:\n",
    "#     for k, v in ham_dict.items():\n",
    "#         ham_dd[k] += v\n",
    "# for spam_dict in spams:\n",
    "#     for k, v in spam_dict.items():\n",
    "#         spam_dd[k] += v\n",
    "# sum(ham_dd.values())\n",
    "\n",
    "# my_sum = 0\n",
    "# for row in training_data:\n",
    "#         my_sum += sum(row[0].values())\n",
    "#         print(my_sum)\n",
    "\n",
    "# ham_dd['to'] + spam_dd['to']\n",
    "# len(set(list(ham_dd.keys()) + list(spam_dd.keys())))\n",
    "# sum(ham_dd.values()) + sum(spam_dd.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2 6\n",
      "0.23427672955974846\n",
      "0.2342767295597484\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def nb_train(training_data):\n",
    "    ham_dd = defaultdict(int)\n",
    "    ham_count = 0\n",
    "    spam_dd = defaultdict(int)\n",
    "    spam_count = 0\n",
    "    for row in training_data:\n",
    "        if row[1] == 'ham':\n",
    "            ham_count += 1\n",
    "            for k, v in row[0].items():\n",
    "                ham_dd[k] += v\n",
    "                \n",
    "        else:\n",
    "            spam_count += 1\n",
    "            for k, v in row[0].items():\n",
    "                spam_dd[k] += v\n",
    "    V = set(list(ham_dd.keys()) + list(spam_dd.keys()))\n",
    "    total_terms = len(V) \n",
    "    N = len(training_data)\n",
    "    ham_total_words = sum(ham_dd.values())\n",
    "    spam_total_words = sum(spam_dd.values())\n",
    "    prior = {}\n",
    "    cond_prob = {}\n",
    "    print(ham_count, spam_count, N)\n",
    "    for c in ['ham', 'spam']:\n",
    "        prior[c] = ham_count / N if c == 'ham' else spam_count / N\n",
    "        cond_prob[c] = {}\n",
    "        for word in V:\n",
    "            if c == 'ham':\n",
    "                cond_prob[c][word] = (ham_dd[word] + 1) / (ham_total_words + total_terms)\n",
    "            else:\n",
    "                cond_prob[c][word] = (spam_dd[word] + 1) / (spam_total_words + total_terms)\n",
    "    return (prior, cond_prob)\n",
    "    \n",
    "\n",
    "def multinomial_nb(training_data, sms):\n",
    "    prior, cond_prob = nb_train(training_data)\n",
    "    prob_ham = prior['ham']\n",
    "    prob_spam = prior['spam']\n",
    "    for word in sms:\n",
    "        if word in cond_prob['ham']:\n",
    "            prob_ham *= cond_prob['ham'][word]\n",
    "        if word in cond_prob['spam']:\n",
    "            prob_spam *= cond_prob['spam'][word]\n",
    "    return prob_spam / prob_ham\n",
    "\n",
    "sms = 'I am not spam'\n",
    "# a, b = nb_train(training_data)\n",
    "print(multinomial_nb(training_data, tokenize(sms)))\n",
    "print(0.2342767295597484)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, you need to **implement** a multinomial naive bayes classifier (i.e., `multinomial_nb()` in the file: `submission.py`) with add-1 smoothing. The input arguments of `multinomial_nb()` are:\n",
    "* `training_data`: pre-processed data stored as a `dictionary`\n",
    "* `sms`: test-sms (i.e., a list of tokens) that you need to categorize as `spam` and/or `ham`\n",
    "\n",
    "The return value of `multinomial_nb()` should be the **ratio** of the probability of sms is spam and the probability of sms is ham. A return value larger than 1 implies the `sms` is spam and vice versa.\n",
    "\n",
    "For example, a sample output is shown in the cell given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'submission_ans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7d7678f1b0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## How we test your implementation...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msubmission_ans\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I am not spam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial_nb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'submission_ans'"
     ]
    }
   ],
   "source": [
    "## How we test your implementation...\n",
    "import submission_ans as submission\n",
    "\n",
    "sms = 'I am not spam'\n",
    "print(submission.multinomial_nb(training_data, tokenize(sms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "You need to complete the function `multinomial_nb()` in the file: `submission.py`. You are allowed to test your submission against sample test cases using online submission system (i.e., https://kg.cse.unsw.edu.au:8318/lab3/).\n",
    "\n",
    "\n",
    "# Test Environment\n",
    "\n",
    "For testing, we have pre-installed the requisite modules and/or libraries in the testing environment. You are only allowed to use following libraries:\n",
    "* python: 3.5.2\n",
    "* pandas: 0.19.2\n",
    "\n",
    "NOTE: You are required to implement the classifier by yourself. You are not allowed to import **sklearn** and/or any other library in Lab3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23427672955974846\n"
     ]
    }
   ],
   "source": [
    "## How we test your implementation...\n",
    "import submission\n",
    "\n",
    "sms = 'I am not spam'\n",
    "print(submission.multinomial_nb(training_data, tokenize(sms)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
